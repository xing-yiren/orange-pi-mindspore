{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4298bfd5",
   "metadata": {},
   "source": [
    "# BERT训推全流程实践\n",
    "\n",
    "本案例通过MindSpore的API来实现BERT的预训练数据构建、模型开发、模型预训练、模型推理全流程实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28131465",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "\n",
    "开发者拿到香橙派开发板后，首先需要进行硬件资源确认、镜像烧录以及CANN和MindSpore版本的升级，才可运行该案例，具体如下：\n",
    "\n",
    "| 香橙派AIpro | 镜像 | CANN Toolkit/Kernels | MindSpore |\n",
    "| :----:| :----: | :----:| :----: |\n",
    "| 20T 24G | Ubuntu | 8.0.0beta1| 2.5.0 |\n",
    "| 20T 24G | Ubuntu | 8.1RC1beta1| 2.6.0 |\n",
    "\n",
    "### 镜像烧录\n",
    "\n",
    "运行该案例需要烧录香橙派官网Ubuntu镜像，参考[镜像烧录](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#1-%E9%95%9C%E5%83%8F%E7%83%A7%E5%BD%95%E4%BB%A5windows%E7%B3%BB%E7%BB%9F%E4%B8%BA%E4%BE%8B)章节。\n",
    "\n",
    "### CANN升级\n",
    "\n",
    "参考[CANN升级](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#3-cann%E5%8D%87%E7%BA%A7)章节。\n",
    "\n",
    "### MindSpore升级\n",
    "\n",
    "参考[MindSpore升级](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#4-mindspore%E5%8D%87%E7%BA%A7)章节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d87f0c5-ea59-4411-8e02-1b338a2dee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(54325:255086409871392,MainProcess):2025-05-16-00:01:47.408.282 [mindspore/context.py:1335] For 'context.set_context', the parameter 'pynative_synchronize' will be deprecated and removed in a future version. Please use the api mindspore.runtime.launch_blocking() instead.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from random import *\n",
    "import mindspore\n",
    "from mindspore import mint\n",
    "from mindspore.nn import Cell, Dense\n",
    "from mindspore.mint import nn, optim\n",
    "mindspore.set_context(pynative_synchronize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf7de2",
   "metadata": {},
   "source": [
    "### 预训练任务的数据构建\n",
    "\n",
    "#### BERT 输入\n",
    "针对句子对相关任务，将两个句子合并为一个句子对输入到Encoder中，[CLS] + 第一个句子 + [SEP] + 第二个句子 + [SEP];  \n",
    "针对单个文本相关任务，[CLS] + 句子 + [SEP]。\n",
    "\n",
    "BERT通过两种无监督任务（Masked Language Modelling 和 Next Sentence Prediction）进行预训练，获取词语和句子级别的特征。\n",
    "#### Next Sentence Prediction (NSP)\n",
    "BERT通过NSP捕捉句子级别的信息，使其可以理解句子与句子之间的联系，从而能够应用于问答或者推理任务。\n",
    "NSP本质上是一个二分类任务，通过输入一个句子对，判断两句话是否为连续句子。\n",
    "\n",
    "#### Masked Language Model (Masked LM)\n",
    "BERT模型通过Masked LM捕捉词语层面的信息。  \n",
    "我们随机将每个句子中15%的词语进行遮盖，替换成掩码\\<mask\\>。在训练过程中，模型会对句子进行“完形填空”，预测这些被遮盖的词语是什么，通过减小被mask词语的损失值来对模型进行优化。    \n",
    "由于\\<mask\\>仅在预训练中出现，为了让预训练和微调中的数据处理尽可能接近，我们在随机mask的时候进行如下操作：\n",
    "- 80%的概率替换为\\<mask\\>\n",
    "- 10%的概率替换为文本中的随机词\n",
    "- 10%的概率不进行替换，保持原有的词元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd4a9097-c20d-45d3-910c-cd1bb7f32a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample IsNext and NotNext to be same in small batch size\n",
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = negative = 0 # 为了记录NSP任务中正样本和负样本的个数，比例最好是在一个batch中接近1:1\n",
    "    while positive != batch_size/2 or negative != batch_size/2:\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences)) # sample random index in sentences\n",
    "        tokens_a, tokens_b = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # MASK LM\n",
    "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "        shuffle(cand_maked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in cand_maked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            if random() < 0.8:  # 80%\n",
    "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
    "            elif random() < 0.5:  # 10%\n",
    "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "\n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # Zero Padding (100% - 15%) tokens\n",
    "        if max_pred > n_pred:\n",
    "            n_pad = max_pred - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, 1]) # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, 0]) # NotNext\n",
    "            negative += 1\n",
    "    return batch\n",
    "# Proprecessing Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185d6ed",
   "metadata": {},
   "source": [
    "### get_attn_pad_mask\n",
    "是为了得到句子中pad的位置信息，给到模型后面，在计算自注意力和交互注意力的时候去掉pad符号的影响\n",
    "\n",
    "比如说，我现在的句子长度是5，在后面注意力机制的部分，我们在计算出来QK转置乘以根号之后，softmax之前，我们得到的形状len_input*len_input ,代表每个单词对其余包含自己的单词的影响力   \n",
    "\n",
    "所以这里需要一个同等大小形状的矩阵，告诉我哪个部分是pad部分，之后在计算softmax之前会把这里置为负无穷大 一定要注意的是这里得到的矩阵形状是batch_size x len_q x len_k，我们是对K中的pad符号进行标识并没有对Q中的做标识，因为没有必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f024fd22-1226-40c1-a99c-cf1eb89471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    \n",
    "    # pad_attn_mask = ops.equal(seq_k, 0)\n",
    "    pad_attn_mask = mint.eq(seq_k, 0)\n",
    "    pad_attn_mask = pad_attn_mask.expand_dims(1) # batch_size x 1 x len_k(=len_q), one is masking\n",
    "\n",
    "    # return ops.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k)) # batch_size x len_q x len_k\n",
    "    return mint.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k)) # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea25a2e",
   "metadata": {},
   "source": [
    "### BERT Embedding\n",
    "输入到BERT模型的信息由三部分内容组成：\n",
    "\n",
    "- 表示内容的token ids  \n",
    "- 表示位置的position ids  \n",
    "- 用于区分不同句子的token type ids\n",
    "\n",
    "三种信息分别进入Embedding层，得到token embeddings、position embeddings与segment embeddings；与Transformer不同，以上三种均为可学习的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ddeca3-e465-4873-9677-f27a21e335e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedding(Cell):\n",
    "    def __init__(self):\n",
    "        super(BertEmbedding, self).__init__()\n",
    "        self.tok_embed = mindspore.nn.Embedding(vocab_size, d_model, dtype=mindspore.float16)  # token embedding\n",
    "        self.pos_embed = mindspore.nn.Embedding(maxlen, d_model, dtype=mindspore.float16)  # position embedding\n",
    "        self.seg_embed = mindspore.nn.Embedding(n_segments, d_model, dtype=mindspore.float16)  # segment(token type) embedding\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "\n",
    "    def construct(self, x, seg):\n",
    "        # MindSpore中表示Tensor形状的属性为shape，区别于PyTorch中的size\n",
    "        seq_len = x.shape[1]\n",
    "        pos = mint.arange(seq_len, dtype=mindspore.int32)\n",
    "        pos = pos.expand_dims(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05498820",
   "metadata": {},
   "source": [
    "### 注意力机制\n",
    "\n",
    "相同的一句话，不同的人听的时候侧重点也可能不同。在自然语言处理中，根据任务内容的不同，句子中需要重点关注的部分也会不同。为此，我们引入注意力机制来判断在执行某个任务时，词在句子中的重要性，并通过注意力分数来表示词的重要程度。分数越高，说明该词对完成该任务的重要性越大。\n",
    "在计算注意力分数时，我们主要参考三个因素：**query**、**key**和**value**。\n",
    "\n",
    "- `query`：任务内容\n",
    "- `key`：索引/标签（帮助定位到答案）\n",
    "- `value`：答案\n",
    "\n",
    "注意力分数的计算公式为：\n",
    "\n",
    "$$\\text{Attention Score}(Q, K)=\\frac{QK^T}{\\sqrt{d_{model}}}$$\n",
    "\n",
    "同时，为了避免`query`（$Q \\in R^{n\\times d_{model}}$）和`key`($K \\in R^{m\\times d_{model}}$)本身的“大小”影响到相似度的计算，我们需要在点乘后除以$\\sqrt{d_{model}}$。\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_{model}}}\\right)V$$\n",
    "\n",
    "在如下代码中，我们实现了scaled dot-product attention的计算， 调用类后，返回的是加权后的value（context）以及注意力权重（attn）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f382a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于mindspore.ops手动实现softmax\n",
    "def manual_softmax(x, dim=-1, dtype=mindspore.float16):\n",
    "    exp_x = mindspore.ops.exp(x - mindspore.ops.max(x, axis=dim, keepdims=True)[0])\n",
    "    return (exp_x / mindspore.ops.sum(exp_x, dim=dim, keepdim=True)).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f824473a-a320-42f1-827d-cb340b92a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(Cell):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        scores = mint.matmul(Q, K.swapaxes(-1, -2)) / mint.sqrt(mindspore.ops.scalar_to_tensor(d_k, mindspore.float16)) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores = scores.masked_fill(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = manual_softmax(scores, dim=-1, dtype=mindspore.float16)\n",
    "        context = mint.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c32476",
   "metadata": {},
   "source": [
    "### 多头注意力（Multi-Head Attention）\n",
    "\n",
    "多头注意力是注意力机制的扩展，它可以使模型通过不同的方式关注输入序列的不同部分，从而提升模型的训练效果。\n",
    "\n",
    "不同于之前一次计算整体输入的注意力分数，多头注意力是多次计算，每次计算输入序列中某一部分的注意力分数，最后再将结果进行整合。\n",
    "\n",
    "多头注意力通过对输入的embedding乘以不同的权重参数$W^{Q}$、$W^{K}$和$W^{V}$，将其映射到多个小维度空间中，我们称之为“头”（head），每个头部会并行计算自己的自注意力分数。\n",
    "\n",
    "$$\\text{head}_i = \\text{Attention}(XW^Q_i, XW^K_i, XW^V_i) = \\text{softmax}\\left(\\frac{Q_iK_i^T}{\\sqrt{d_{k}}}\\right)V_i$$\n",
    "\n",
    "$W^Q_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$、$W^K_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$和$W^V_i \\in \\mathbb{R}^{d_{model}\\times d_{v}}$为可学习的权重参数。一般为了平衡计算成本，我们会取$d_k = d_v = d_{model} / n_{head}$。\n",
    "\n",
    "在获得多组自注意力分数后，我们将结果拼接到一起，得到多头注意力的最终输出。$W^O$为可学习的权重参数，用于将拼接后的多头注意力输出映射回原来的维度。\n",
    "\n",
    "$$\\text{MultiHead}(Q, K, V)=\\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O$$\n",
    "\n",
    "简单来说，在多头注意力中，每个头部可以'解读'输入内容的不同方面，比如：捕捉全局依赖关系、关注特定语境下的词元、识别词和词之间的语法关系等。\n",
    "\n",
    "### Add & Norm\n",
    "\n",
    "Add & Norm层本质上是残差连接后紧接了一个LayerNorm层。\n",
    "\n",
    "$$\\text{AddNorm}(x) = \\text{LayerNorm}(x + \\text{Sublayer}(x))$$\n",
    "\n",
    "- Add：残差连接，帮助缓解网络退化问题，注意需要满足$x$与$\\text{SubLayer}(x)的形状一致$；\n",
    "- Norm：Layer Norm，层归一化，帮助模型更快地进行收敛；\n",
    "\n",
    "#### MindSpore与PyTorch的全连接层API对比\n",
    "\n",
    "MindSpore中构造全连接层的API为nn.Dense，区别于PyTorch中的nn.Linear，且二者权重初始化不同：\n",
    "\n",
    "- MindSpore：weight默认初始化为'normal'分布，bias默认初始化为零\n",
    "- PyTorch：weight默认初始化为kaiming_uniform，bias默认初始化为uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef49a217-d48b-4a89-babd-ee2722745316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Cell):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = Dense(d_model, d_k * n_heads, dtype=mindspore.float16)\n",
    "        self.W_K = Dense(d_model, d_k * n_heads, dtype=mindspore.float16)\n",
    "        self.W_V = Dense(d_model, d_v * n_heads, dtype=mindspore.float16)\n",
    "        self.W_O = Dense(n_heads * d_v, d_model, dtype=mindspore.float16)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "\n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        # 注意区分MindSpore中的Tensor.transpose与PyTorch中的Tesor.transpose\n",
    "        # MindSpore中的transpose为对所有维度进行重排，PyTorch中的transpose为对两个维度进行交换\n",
    "        # MindSpore中对Tensor的两个维度进行交换的接口应为swapaxes\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).swapaxes(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).swapaxes(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).swapaxes(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "        \n",
    "        attn_mask = attn_mask.expand_dims(1)\n",
    "        attn_mask = mint.tile(attn_mask, (1, n_heads, 1, 1))\n",
    "        \n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = self.attn(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.swapaxes(1, 2).view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.W_O(context)\n",
    "        return self.norm(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa752c",
   "metadata": {},
   "source": [
    "### 基于位置的前馈神经网络 （Position-Wise Feed-Forward Network）\n",
    "基于位置的前馈神经网络被用来对输入中的每个位置进行非线性变换。它由两个线性层组成，层与层之间需要经过GELU激活函数。\n",
    "\n",
    "FFN(𝑥)=GELU(𝑥𝑊1+𝑏1)𝑊2+𝑏2\n",
    " \n",
    "相比固定的GELU函数，基于位置的前馈神经网络可以处理更加复杂的关系，并且由于前馈网络是基于位置的，可以捕获到不同位置的信息，并为每个位置提供不同的转换。\n",
    "\n",
    "#### MindSpore与PyTorch的GELU激活函数对比\n",
    "\n",
    "对于API的功能对齐，注意MindSpore和PyTorch中有些API即使名称宏观功能一致，默认传参会出现差别，如GELU接口。\n",
    "\n",
    "- MindSpore：入参`approximate`为`boolean`类型，默认为True，如果为True采取tanh方法做优化近似，反之采取erf方法\n",
    "- PyTorch：入参`approximate`为`string`类型，默认为'none'，如果为'tanh'采取tanh方法进行优化近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ac0741-2515-413c-8aec-67a6ab654f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(Cell):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = Dense(d_model, d_ff, dtype=mindspore.float16)\n",
    "        self.fc2 = Dense(d_ff, d_model, dtype=mindspore.float16)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(self.activation(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b45114",
   "metadata": {},
   "source": [
    "### Encoder Layer\n",
    "我们首先实现encoder中的一个层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cac523ae-53a0-4678-a205-6f51d2e4f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Cell):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        # print('enc_inputs: ', enc_inputs.dtype)\n",
    "        enc_inputs = enc_inputs.astype(mindspore.float16)\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91516bc4",
   "metadata": {},
   "source": [
    "\n",
    "### BERT\n",
    "\n",
    "将上面实现的encoder层堆叠`n_layers`次，并添加token embeddings、position embeddings与segment embeddings。\n",
    "\n",
    "#### BERT 输出\n",
    "BERT会针对每一个位置输出大小为hidden size的向量，在下游任务中，会根据任务内容的不同，选取不同的向量放入输出层。\n",
    "\n",
    "我们一般称[CLS]经过线性层+激活函数tanh的输出为pooler output，用于句子级别的分类/回归任务;  \n",
    "我们一般称BERT输出的每个位置对应的vector为sequence output,用于词语级别的分类任务；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2891fc39-ccf0-4f8c-875a-821ad85ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(Cell):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = BertEmbedding()\n",
    "        self.layers = mindspore.nn.CellList([EncoderLayer() for _ in range(n_layers)])\n",
    "        self.fc = Dense(d_model, d_model, dtype=mindspore.float16)\n",
    "        self.activ1 = nn.Tanh()\n",
    "        self.linear = Dense(d_model, d_model, dtype=mindspore.float16)\n",
    "        self.activ2 = nn.GELU()\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "        self.classifier = Dense(d_model, 2, dtype=mindspore.float16)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.embedding_table\n",
    "        n_vocab, n_dim = embed_weight.shape\n",
    "        self.decoder = Dense(n_dim, n_vocab, has_bias=False, dtype=mindspore.float16)\n",
    "        self.decoder.weight = embed_weight.to(mindspore.float16)\n",
    "        self.decoder_bias = mindspore.Parameter(mint.zeros(n_vocab, dtype=mindspore.float16), 'decoder_bias')\n",
    "\n",
    "    def construct(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0]))  # [batch_size, d_model]\n",
    "        logits_clsf = self.classifier(h_pooled)  # [batch_size, 2]\n",
    "        \n",
    "        # 使用ops.gather替代gather_elements，无需扩展masked_pos为三维\n",
    "\n",
    "        h_masked = mindspore.ops.gather(output, masked_pos, 1, batch_dims=1)  # [batch_size, max_pred, d_model]\n",
    "\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias  # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9391e0d9-f019-4d3e-9c6c-fb57a3b6a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Parameters\n",
    "maxlen = 30 # maximum of length\n",
    "batch_size = 6\n",
    "max_pred = 5  # max tokens of prediction\n",
    "n_layers = 6 # number of Encoder of Encoder Layer\n",
    "n_heads = 12 # number of heads in Multi-Head Attention\n",
    "d_model = 768 # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7c275",
   "metadata": {},
   "source": [
    "### 构建词典\n",
    "将每个词元映射到数字索引中，词元和数字索引所构成的集合叫做词典（vocabulary）。\n",
    "\n",
    "在构建词典中，我们使用了4个特殊词元。\n",
    "[PAD]：填充词元（padding），当句子长度不够时将句子填充至统一长度；  \n",
    "[CLS]：句子级别信息；  \n",
    "[SEP]: 结束词元，用来标注一个句子的结束；  \n",
    "[MASK]: mask词元；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24608b11-440c-4fb6-b070-45ff3d82c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Hello, how are you? I am Romeo.\\n'\n",
    "    'Hello, Romeo My name is Juliet. Nice to meet you.\\n'\n",
    "    'Nice meet you too. How are you today?\\n'\n",
    "    'Great. My baseball team won the competition.\\n'\n",
    "    'Oh Congratulations, Juliet\\n'\n",
    "    'Thanks you Romeo'\n",
    ")\n",
    "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # filter '.', ',', '?', '!'\n",
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
    "for i, w in enumerate(word_list):\n",
    "    word_dict[w] = i + 4\n",
    "number_dict = {i: w for i, w in enumerate(word_dict)}\n",
    "vocab_size = len(word_dict)\n",
    "token_list = list()\n",
    "for sentence in sentences:\n",
    "    arr = [word_dict[s] for s in sentence.split()]\n",
    "    token_list.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4fa44",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "实例化BERT模型。\n",
    "\n",
    "### 定义损失函数与优化器。\n",
    "\n",
    "- 损失函数：定义如何计算模型输出(logits)与目标(targets)之间的误差，这里可以使用交叉熵损失（CrossEntropyLoss）  \n",
    "- 优化器：MindSpore将模型优化算法的实现称为优化器。优化器内部定义了模型的参数优化过程（即梯度如何更新至模型参数），所有优化逻辑都封装在优化器对象中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4e30ab-9e7d-4868-893f-b160cf090959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()\n",
    "criterion = mindspore.ops.SoftmaxCrossEntropyWithLogits()\n",
    "optimizer = mindspore.nn.Adam(model.trainable_params(), learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346774e",
   "metadata": {},
   "source": [
    "### 模型训练逻辑\n",
    "\n",
    "MindSpore在模型训练中采取函数式编程，即：\n",
    "\n",
    "1. Network+loss function直接构造正向函数\n",
    "2. 函数变换，获得梯度计算（反向传播）函数\n",
    "3. 构造训练过程函数\n",
    "4. 调用函数进行训练\n",
    "\n",
    "和PyTorch相比，两个框架在前向计算的调用方式一致，但在反向计算中MindSpore采用函数微分，PyTorch采用数据流微分，最后在梯度更新中，二者流程相同，但底层实现逻辑不同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef3603-8154-495b-9e00-5916c65c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import amp\n",
    "\n",
    "loss_scaler = amp.StaticLossScaler(scale_value=2**10)\n",
    "\n",
    "# 构造正向函数\n",
    "def forward(input_ids, segment_ids, masked_pos, masked_tokens, isNext):\n",
    "    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "    logits_lm = mint.reshape(logits_lm, (-1, vocab_size)) # [batch_size * max_pred, n_vocab]\n",
    "    masked_tokens = mint.reshape(masked_tokens, (-1,)) # [batch_size * max_pred]\n",
    "    masked_tokens_onehot = nn.functional.one_hot(masked_tokens.astype(mindspore.int32), vocab_size)\n",
    "    \n",
    "    loss_lm = criterion(logits_lm, masked_tokens_onehot.to(logits_lm.dtype))[0]\n",
    "    loss_lm = loss_lm.mean()\n",
    "    # scaled_loss_lm = loss_scaler.scale(loss_lm)\n",
    "\n",
    "    isNext_onehot = nn.functional.one_hot(isNext.astype(mindspore.int32), 2)\n",
    "    loss_clsf = criterion(logits_clsf, isNext_onehot.to(logits_clsf.dtype))[0]\n",
    "    loss_clsf = loss_clsf.mean()\n",
    "    # scaled_loss_clsf = loss_scaler.scale(loss_clsf)\n",
    "\n",
    "    return loss_scaler.scale(loss_lm + loss_clsf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c1c152d-d4f0-4a66-b3e2-5cbf76d15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数变换，获得微分函数\n",
    "grad_fn = mindspore.value_and_grad(forward, None, optimizer.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa084dc",
   "metadata": {},
   "source": [
    "MindSpore提供了jit装饰器，可以通过修饰Python函数或者Python类的成员函数，使其被编译成计算图，通过图优化等技术提高运行速度。在这种方式下，我们可以简单地对想要进行性能优化的模块来进行图编译加速，而模型的其他部分仍旧使用解释执行方式，不丢失动态图的灵活性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2cd05a5-b034-46cd-980e-dfb15e7b6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义单步训练逻辑\n",
    "\n",
    "def train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext):\n",
    "    # 反向传播获取梯度\n",
    "    loss, grads = grad_fn(input_ids, segment_ids, masked_pos, masked_tokens, isNext)\n",
    "    unscaled_loss = loss_scaler.unscale(loss)\n",
    "    unscaled_grads = loss_scaler.unscale(grads)\n",
    "    # 模型权重更新\n",
    "    optimizer(unscaled_grads)\n",
    "    return unscaled_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bf550b-8239-440d-9fda-c556dee4552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001\n",
      ".....loss: 3.855\n",
      "time: 74.99734854698181\n",
      "Epoch: 0001 cost = 3.855469\n",
      "Epoch: 0002\n",
      "loss: 2.363\n",
      "time: 0.5860943794250488\n",
      "Epoch: 0002 cost = 2.363281\n"
     ]
    }
   ],
   "source": [
    "# 构建数据\n",
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(mindspore.Tensor, zip(*batch))\n",
    "\n",
    "# 启动模型训练\n",
    "import time\n",
    "model.set_train()\n",
    "for epoch in range(2):\n",
    "    print('Epoch:', '%04d' % (epoch + 1))\n",
    "    s_time = time.time()\n",
    "    loss = train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext)\n",
    "    print('loss:', loss.asnumpy())\n",
    "\n",
    "    e_time = time.time()\n",
    "    print('time:', e_time - s_time)\n",
    "    # loss = train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext) # for sentence classification\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0570e5",
   "metadata": {},
   "source": [
    "### 以batch中的第一组语句batch[0]为例，进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8afdd6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本内容：\n",
      " Hello, how are you? I am Romeo.\n",
      "Hello, Romeo My name is Juliet. Nice to meet you.\n",
      "Nice meet you too. How are you today?\n",
      "Great. My baseball team won the competition.\n",
      "Oh Congratulations, Juliet\n",
      "Thanks you Romeo\n",
      "掩码之后的文本：\n",
      "['[CLS]', 'hello', 'romeo', '[MASK]', 'name', 'is', 'juliet', 'nice', 'to', 'meet', 'you', '[SEP]', '[MASK]', 'you', 'romeo', '[SEP]']\n",
      "masked tokens list :  [Tensor(shape=[], dtype=Int64, value= 6), Tensor(shape=[], dtype=Int64, value= 7)]\n",
      "predict masked tokens list :  []\n",
      ".isNext :  False\n",
      "predict isNext :  True\n"
     ]
    }
   ],
   "source": [
    "# Predict mask tokens ans isNext\n",
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(mindspore.Tensor, zip(batch[0]))\n",
    "print(f\"文本内容：\\n {text}\")\n",
    "print(\"掩码之后的文本：\")\n",
    "print([number_dict[int(w.asnumpy())] for w in input_ids[0] if number_dict[int(w.asnumpy())] != '[PAD]'])\n",
    "\n",
    "\n",
    "logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "logits_lm_reshaped = mint.reshape(logits_lm, (-1, vocab_size)) # [batch_size * max_pred, n_vocab]\n",
    "masked_tokens_reshaped = mint.reshape(masked_tokens, (-1,)) # [batch_size * max_pred]\n",
    "masked_tokens_onehot = nn.functional.one_hot(masked_tokens_reshaped.astype(mindspore.int32), vocab_size)\n",
    "loss_lm = criterion(logits_lm_reshaped, masked_tokens_onehot.to(logits_lm.dtype))[0]\n",
    "\n",
    "loss_lm = loss_lm.mean()\n",
    "\n",
    "logits_lm = logits_lm.argmax(2)[0].asnumpy()\n",
    "\n",
    "print('masked tokens list : ', [pos for pos in masked_tokens[0] if pos != 0])\n",
    "print('predict masked tokens list : ', [pos for pos in logits_lm if pos != 0])\n",
    "\n",
    "logits_clsf = logits_clsf.argmax(1).asnumpy()[0]\n",
    "\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_clsf else False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

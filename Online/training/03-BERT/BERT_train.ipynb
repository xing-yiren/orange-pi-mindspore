{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4298bfd5",
   "metadata": {},
   "source": [
    "# BERTè®­æ¨å…¨æµç¨‹å®è·µ\n",
    "\n",
    "æœ¬æ¡ˆä¾‹é€šè¿‡MindSporeçš„APIæ¥å®ç°BERTçš„é¢„è®­ç»ƒæ•°æ®æ„å»ºã€æ¨¡å‹å¼€å‘ã€æ¨¡å‹é¢„è®­ç»ƒã€æ¨¡å‹æ¨ç†å…¨æµç¨‹å®è·µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28131465",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "å¼€å‘è€…æ‹¿åˆ°é¦™æ©™æ´¾å¼€å‘æ¿åï¼Œé¦–å…ˆéœ€è¦è¿›è¡Œç¡¬ä»¶èµ„æºç¡®è®¤ã€é•œåƒçƒ§å½•ä»¥åŠCANNå’ŒMindSporeç‰ˆæœ¬çš„å‡çº§ï¼Œæ‰å¯è¿è¡Œè¯¥æ¡ˆä¾‹ï¼Œå…·ä½“å¦‚ä¸‹ï¼š\n",
    "\n",
    "| é¦™æ©™æ´¾AIpro | é•œåƒ | CANN Toolkit/Kernels | MindSpore |\n",
    "| :----:| :----: | :----:| :----: |\n",
    "| 20T 24G | Ubuntu | 8.0.0beta1| 2.5.0 |\n",
    "| 20T 24G | Ubuntu | 8.1RC1beta1| 2.6.0 |\n",
    "\n",
    "### é•œåƒçƒ§å½•\n",
    "\n",
    "è¿è¡Œè¯¥æ¡ˆä¾‹éœ€è¦çƒ§å½•é¦™æ©™æ´¾å®˜ç½‘Ubuntué•œåƒï¼Œå‚è€ƒ[é•œåƒçƒ§å½•](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#1-%E9%95%9C%E5%83%8F%E7%83%A7%E5%BD%95%E4%BB%A5windows%E7%B3%BB%E7%BB%9F%E4%B8%BA%E4%BE%8B)ç« èŠ‚ã€‚\n",
    "\n",
    "### CANNå‡çº§\n",
    "\n",
    "å‚è€ƒ[CANNå‡çº§](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#3-cann%E5%8D%87%E7%BA%A7)ç« èŠ‚ã€‚\n",
    "\n",
    "### MindSporeå‡çº§\n",
    "\n",
    "å‚è€ƒ[MindSporeå‡çº§](https://www.mindspore.cn/tutorials/zh-CN/r2.6.0rc1/orange_pi/environment_setup.html#4-mindspore%E5%8D%87%E7%BA%A7)ç« èŠ‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d87f0c5-ea59-4411-8e02-1b338a2dee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(54325:255086409871392,MainProcess):2025-05-16-00:01:47.408.282 [mindspore/context.py:1335] For 'context.set_context', the parameter 'pynative_synchronize' will be deprecated and removed in a future version. Please use the api mindspore.runtime.launch_blocking() instead.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from random import *\n",
    "import mindspore\n",
    "from mindspore import mint\n",
    "from mindspore.nn import Cell, Dense\n",
    "from mindspore.mint import nn, optim\n",
    "mindspore.set_context(pynative_synchronize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf7de2",
   "metadata": {},
   "source": [
    "### é¢„è®­ç»ƒä»»åŠ¡çš„æ•°æ®æ„å»º\n",
    "\n",
    "#### BERT è¾“å…¥\n",
    "é’ˆå¯¹å¥å­å¯¹ç›¸å…³ä»»åŠ¡ï¼Œå°†ä¸¤ä¸ªå¥å­åˆå¹¶ä¸ºä¸€ä¸ªå¥å­å¯¹è¾“å…¥åˆ°Encoderä¸­ï¼Œ[CLS] + ç¬¬ä¸€ä¸ªå¥å­ + [SEP] + ç¬¬äºŒä¸ªå¥å­ + [SEP];  \n",
    "é’ˆå¯¹å•ä¸ªæ–‡æœ¬ç›¸å…³ä»»åŠ¡ï¼Œ[CLS] + å¥å­ + [SEP]ã€‚\n",
    "\n",
    "BERTé€šè¿‡ä¸¤ç§æ— ç›‘ç£ä»»åŠ¡ï¼ˆMasked Language Modelling å’Œ Next Sentence Predictionï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œè·å–è¯è¯­å’Œå¥å­çº§åˆ«çš„ç‰¹å¾ã€‚\n",
    "#### Next Sentence Prediction (NSP)\n",
    "BERTé€šè¿‡NSPæ•æ‰å¥å­çº§åˆ«çš„ä¿¡æ¯ï¼Œä½¿å…¶å¯ä»¥ç†è§£å¥å­ä¸å¥å­ä¹‹é—´çš„è”ç³»ï¼Œä»è€Œèƒ½å¤Ÿåº”ç”¨äºé—®ç­”æˆ–è€…æ¨ç†ä»»åŠ¡ã€‚\n",
    "NSPæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªäºŒåˆ†ç±»ä»»åŠ¡ï¼Œé€šè¿‡è¾“å…¥ä¸€ä¸ªå¥å­å¯¹ï¼Œåˆ¤æ–­ä¸¤å¥è¯æ˜¯å¦ä¸ºè¿ç»­å¥å­ã€‚\n",
    "\n",
    "#### Masked Language Model (Masked LM)\n",
    "BERTæ¨¡å‹é€šè¿‡Masked LMæ•æ‰è¯è¯­å±‚é¢çš„ä¿¡æ¯ã€‚  \n",
    "æˆ‘ä»¬éšæœºå°†æ¯ä¸ªå¥å­ä¸­15%çš„è¯è¯­è¿›è¡Œé®ç›–ï¼Œæ›¿æ¢æˆæ©ç \\<mask\\>ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šå¯¹å¥å­è¿›è¡Œâ€œå®Œå½¢å¡«ç©ºâ€ï¼Œé¢„æµ‹è¿™äº›è¢«é®ç›–çš„è¯è¯­æ˜¯ä»€ä¹ˆï¼Œé€šè¿‡å‡å°è¢«maskè¯è¯­çš„æŸå¤±å€¼æ¥å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚    \n",
    "ç”±äº\\<mask\\>ä»…åœ¨é¢„è®­ç»ƒä¸­å‡ºç°ï¼Œä¸ºäº†è®©é¢„è®­ç»ƒå’Œå¾®è°ƒä¸­çš„æ•°æ®å¤„ç†å°½å¯èƒ½æ¥è¿‘ï¼Œæˆ‘ä»¬åœ¨éšæœºmaskçš„æ—¶å€™è¿›è¡Œå¦‚ä¸‹æ“ä½œï¼š\n",
    "- 80%çš„æ¦‚ç‡æ›¿æ¢ä¸º\\<mask\\>\n",
    "- 10%çš„æ¦‚ç‡æ›¿æ¢ä¸ºæ–‡æœ¬ä¸­çš„éšæœºè¯\n",
    "- 10%çš„æ¦‚ç‡ä¸è¿›è¡Œæ›¿æ¢ï¼Œä¿æŒåŸæœ‰çš„è¯å…ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd4a9097-c20d-45d3-910c-cd1bb7f32a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample IsNext and NotNext to be same in small batch size\n",
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = negative = 0 # ä¸ºäº†è®°å½•NSPä»»åŠ¡ä¸­æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„ä¸ªæ•°ï¼Œæ¯”ä¾‹æœ€å¥½æ˜¯åœ¨ä¸€ä¸ªbatchä¸­æ¥è¿‘1:1\n",
    "    while positive != batch_size/2 or negative != batch_size/2:\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences)) # sample random index in sentences\n",
    "        tokens_a, tokens_b = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # MASK LM\n",
    "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "        shuffle(cand_maked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in cand_maked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            if random() < 0.8:  # 80%\n",
    "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
    "            elif random() < 0.5:  # 10%\n",
    "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "\n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # Zero Padding (100% - 15%) tokens\n",
    "        if max_pred > n_pred:\n",
    "            n_pad = max_pred - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, 1]) # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, 0]) # NotNext\n",
    "            negative += 1\n",
    "    return batch\n",
    "# Proprecessing Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185d6ed",
   "metadata": {},
   "source": [
    "### get_attn_pad_mask\n",
    "æ˜¯ä¸ºäº†å¾—åˆ°å¥å­ä¸­padçš„ä½ç½®ä¿¡æ¯ï¼Œç»™åˆ°æ¨¡å‹åé¢ï¼Œåœ¨è®¡ç®—è‡ªæ³¨æ„åŠ›å’Œäº¤äº’æ³¨æ„åŠ›çš„æ—¶å€™å»æ‰padç¬¦å·çš„å½±å“\n",
    "\n",
    "æ¯”å¦‚è¯´ï¼Œæˆ‘ç°åœ¨çš„å¥å­é•¿åº¦æ˜¯5ï¼Œåœ¨åé¢æ³¨æ„åŠ›æœºåˆ¶çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬åœ¨è®¡ç®—å‡ºæ¥QKè½¬ç½®ä¹˜ä»¥æ ¹å·ä¹‹åï¼Œsoftmaxä¹‹å‰ï¼Œæˆ‘ä»¬å¾—åˆ°çš„å½¢çŠ¶len_input*len_input ,ä»£è¡¨æ¯ä¸ªå•è¯å¯¹å…¶ä½™åŒ…å«è‡ªå·±çš„å•è¯çš„å½±å“åŠ›   \n",
    "\n",
    "æ‰€ä»¥è¿™é‡Œéœ€è¦ä¸€ä¸ªåŒç­‰å¤§å°å½¢çŠ¶çš„çŸ©é˜µï¼Œå‘Šè¯‰æˆ‘å“ªä¸ªéƒ¨åˆ†æ˜¯padéƒ¨åˆ†ï¼Œä¹‹ååœ¨è®¡ç®—softmaxä¹‹å‰ä¼šæŠŠè¿™é‡Œç½®ä¸ºè´Ÿæ— ç©·å¤§ ä¸€å®šè¦æ³¨æ„çš„æ˜¯è¿™é‡Œå¾—åˆ°çš„çŸ©é˜µå½¢çŠ¶æ˜¯batch_size x len_q x len_kï¼Œæˆ‘ä»¬æ˜¯å¯¹Kä¸­çš„padç¬¦å·è¿›è¡Œæ ‡è¯†å¹¶æ²¡æœ‰å¯¹Qä¸­çš„åšæ ‡è¯†ï¼Œå› ä¸ºæ²¡æœ‰å¿…è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f024fd22-1226-40c1-a99c-cf1eb89471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    \n",
    "    # pad_attn_mask = ops.equal(seq_k, 0)\n",
    "    pad_attn_mask = mint.eq(seq_k, 0)\n",
    "    pad_attn_mask = pad_attn_mask.expand_dims(1) # batch_size x 1 x len_k(=len_q), one is masking\n",
    "\n",
    "    # return ops.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k)) # batch_size x len_q x len_k\n",
    "    return mint.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k)) # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea25a2e",
   "metadata": {},
   "source": [
    "### BERT Embedding\n",
    "è¾“å…¥åˆ°BERTæ¨¡å‹çš„ä¿¡æ¯ç”±ä¸‰éƒ¨åˆ†å†…å®¹ç»„æˆï¼š\n",
    "\n",
    "- è¡¨ç¤ºå†…å®¹çš„token ids  \n",
    "- è¡¨ç¤ºä½ç½®çš„position ids  \n",
    "- ç”¨äºåŒºåˆ†ä¸åŒå¥å­çš„token type ids\n",
    "\n",
    "ä¸‰ç§ä¿¡æ¯åˆ†åˆ«è¿›å…¥Embeddingå±‚ï¼Œå¾—åˆ°token embeddingsã€position embeddingsä¸segment embeddingsï¼›ä¸Transformerä¸åŒï¼Œä»¥ä¸Šä¸‰ç§å‡ä¸ºå¯å­¦ä¹ çš„ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ddeca3-e465-4873-9677-f27a21e335e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedding(Cell):\n",
    "    def __init__(self):\n",
    "        super(BertEmbedding, self).__init__()\n",
    "        self.tok_embed = mindspore.nn.Embedding(vocab_size, d_model, dtype=mindspore.float16)  # token embedding\n",
    "        self.pos_embed = mindspore.nn.Embedding(maxlen, d_model, dtype=mindspore.float16)  # position embedding\n",
    "        self.seg_embed = mindspore.nn.Embedding(n_segments, d_model, dtype=mindspore.float16)  # segment(token type) embedding\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "\n",
    "    def construct(self, x, seg):\n",
    "        # MindSporeä¸­è¡¨ç¤ºTensorå½¢çŠ¶çš„å±æ€§ä¸ºshapeï¼ŒåŒºåˆ«äºPyTorchä¸­çš„size\n",
    "        seq_len = x.shape[1]\n",
    "        pos = mint.arange(seq_len, dtype=mindspore.int32)\n",
    "        pos = pos.expand_dims(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05498820",
   "metadata": {},
   "source": [
    "### æ³¨æ„åŠ›æœºåˆ¶\n",
    "\n",
    "ç›¸åŒçš„ä¸€å¥è¯ï¼Œä¸åŒçš„äººå¬çš„æ—¶å€™ä¾§é‡ç‚¹ä¹Ÿå¯èƒ½ä¸åŒã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œæ ¹æ®ä»»åŠ¡å†…å®¹çš„ä¸åŒï¼Œå¥å­ä¸­éœ€è¦é‡ç‚¹å…³æ³¨çš„éƒ¨åˆ†ä¹Ÿä¼šä¸åŒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ¥åˆ¤æ–­åœ¨æ‰§è¡ŒæŸä¸ªä»»åŠ¡æ—¶ï¼Œè¯åœ¨å¥å­ä¸­çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›åˆ†æ•°æ¥è¡¨ç¤ºè¯çš„é‡è¦ç¨‹åº¦ã€‚åˆ†æ•°è¶Šé«˜ï¼Œè¯´æ˜è¯¥è¯å¯¹å®Œæˆè¯¥ä»»åŠ¡çš„é‡è¦æ€§è¶Šå¤§ã€‚\n",
    "åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°æ—¶ï¼Œæˆ‘ä»¬ä¸»è¦å‚è€ƒä¸‰ä¸ªå› ç´ ï¼š**query**ã€**key**å’Œ**value**ã€‚\n",
    "\n",
    "- `query`ï¼šä»»åŠ¡å†…å®¹\n",
    "- `key`ï¼šç´¢å¼•/æ ‡ç­¾ï¼ˆå¸®åŠ©å®šä½åˆ°ç­”æ¡ˆï¼‰\n",
    "- `value`ï¼šç­”æ¡ˆ\n",
    "\n",
    "æ³¨æ„åŠ›åˆ†æ•°çš„è®¡ç®—å…¬å¼ä¸ºï¼š\n",
    "\n",
    "$$\\text{Attention Score}(Q, K)=\\frac{QK^T}{\\sqrt{d_{model}}}$$\n",
    "\n",
    "åŒæ—¶ï¼Œä¸ºäº†é¿å…`query`ï¼ˆ$Q \\in R^{n\\times d_{model}}$ï¼‰å’Œ`key`($K \\in R^{m\\times d_{model}}$)æœ¬èº«çš„â€œå¤§å°â€å½±å“åˆ°ç›¸ä¼¼åº¦çš„è®¡ç®—ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç‚¹ä¹˜åé™¤ä»¥$\\sqrt{d_{model}}$ã€‚\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_{model}}}\\right)V$$\n",
    "\n",
    "åœ¨å¦‚ä¸‹ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†scaled dot-product attentionçš„è®¡ç®—ï¼Œ è°ƒç”¨ç±»åï¼Œè¿”å›çš„æ˜¯åŠ æƒåçš„valueï¼ˆcontextï¼‰ä»¥åŠæ³¨æ„åŠ›æƒé‡ï¼ˆattnï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f382a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºäºmindspore.opsæ‰‹åŠ¨å®ç°softmax\n",
    "def manual_softmax(x, dim=-1, dtype=mindspore.float16):\n",
    "    exp_x = mindspore.ops.exp(x - mindspore.ops.max(x, axis=dim, keepdims=True)[0])\n",
    "    return (exp_x / mindspore.ops.sum(exp_x, dim=dim, keepdim=True)).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f824473a-a320-42f1-827d-cb340b92a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(Cell):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        scores = mint.matmul(Q, K.swapaxes(-1, -2)) / mint.sqrt(mindspore.ops.scalar_to_tensor(d_k, mindspore.float16)) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores = scores.masked_fill(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = manual_softmax(scores, dim=-1, dtype=mindspore.float16)\n",
    "        context = mint.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c32476",
   "metadata": {},
   "source": [
    "### å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰\n",
    "\n",
    "å¤šå¤´æ³¨æ„åŠ›æ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„æ‰©å±•ï¼Œå®ƒå¯ä»¥ä½¿æ¨¡å‹é€šè¿‡ä¸åŒçš„æ–¹å¼å…³æ³¨è¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†ï¼Œä»è€Œæå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚\n",
    "\n",
    "ä¸åŒäºä¹‹å‰ä¸€æ¬¡è®¡ç®—æ•´ä½“è¾“å…¥çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¤šå¤´æ³¨æ„åŠ›æ˜¯å¤šæ¬¡è®¡ç®—ï¼Œæ¯æ¬¡è®¡ç®—è¾“å…¥åºåˆ—ä¸­æŸä¸€éƒ¨åˆ†çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œæœ€åå†å°†ç»“æœè¿›è¡Œæ•´åˆã€‚\n",
    "\n",
    "å¤šå¤´æ³¨æ„åŠ›é€šè¿‡å¯¹è¾“å…¥çš„embeddingä¹˜ä»¥ä¸åŒçš„æƒé‡å‚æ•°$W^{Q}$ã€$W^{K}$å’Œ$W^{V}$ï¼Œå°†å…¶æ˜ å°„åˆ°å¤šä¸ªå°ç»´åº¦ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œå¤´â€ï¼ˆheadï¼‰ï¼Œæ¯ä¸ªå¤´éƒ¨ä¼šå¹¶è¡Œè®¡ç®—è‡ªå·±çš„è‡ªæ³¨æ„åŠ›åˆ†æ•°ã€‚\n",
    "\n",
    "$$\\text{head}_i = \\text{Attention}(XW^Q_i, XW^K_i, XW^V_i) = \\text{softmax}\\left(\\frac{Q_iK_i^T}{\\sqrt{d_{k}}}\\right)V_i$$\n",
    "\n",
    "$W^Q_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$ã€$W^K_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$å’Œ$W^V_i \\in \\mathbb{R}^{d_{model}\\times d_{v}}$ä¸ºå¯å­¦ä¹ çš„æƒé‡å‚æ•°ã€‚ä¸€èˆ¬ä¸ºäº†å¹³è¡¡è®¡ç®—æˆæœ¬ï¼Œæˆ‘ä»¬ä¼šå–$d_k = d_v = d_{model} / n_{head}$ã€‚\n",
    "\n",
    "åœ¨è·å¾—å¤šç»„è‡ªæ³¨æ„åŠ›åˆ†æ•°åï¼Œæˆ‘ä»¬å°†ç»“æœæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œå¾—åˆ°å¤šå¤´æ³¨æ„åŠ›çš„æœ€ç»ˆè¾“å‡ºã€‚$W^O$ä¸ºå¯å­¦ä¹ çš„æƒé‡å‚æ•°ï¼Œç”¨äºå°†æ‹¼æ¥åçš„å¤šå¤´æ³¨æ„åŠ›è¾“å‡ºæ˜ å°„å›åŸæ¥çš„ç»´åº¦ã€‚\n",
    "\n",
    "$$\\text{MultiHead}(Q, K, V)=\\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O$$\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œåœ¨å¤šå¤´æ³¨æ„åŠ›ä¸­ï¼Œæ¯ä¸ªå¤´éƒ¨å¯ä»¥'è§£è¯»'è¾“å…¥å†…å®¹çš„ä¸åŒæ–¹é¢ï¼Œæ¯”å¦‚ï¼šæ•æ‰å…¨å±€ä¾èµ–å…³ç³»ã€å…³æ³¨ç‰¹å®šè¯­å¢ƒä¸‹çš„è¯å…ƒã€è¯†åˆ«è¯å’Œè¯ä¹‹é—´çš„è¯­æ³•å…³ç³»ç­‰ã€‚\n",
    "\n",
    "### Add & Norm\n",
    "\n",
    "Add & Normå±‚æœ¬è´¨ä¸Šæ˜¯æ®‹å·®è¿æ¥åç´§æ¥äº†ä¸€ä¸ªLayerNormå±‚ã€‚\n",
    "\n",
    "$$\\text{AddNorm}(x) = \\text{LayerNorm}(x + \\text{Sublayer}(x))$$\n",
    "\n",
    "- Addï¼šæ®‹å·®è¿æ¥ï¼Œå¸®åŠ©ç¼“è§£ç½‘ç»œé€€åŒ–é—®é¢˜ï¼Œæ³¨æ„éœ€è¦æ»¡è¶³$x$ä¸$\\text{SubLayer}(x)çš„å½¢çŠ¶ä¸€è‡´$ï¼›\n",
    "- Normï¼šLayer Normï¼Œå±‚å½’ä¸€åŒ–ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¿«åœ°è¿›è¡Œæ”¶æ•›ï¼›\n",
    "\n",
    "#### MindSporeä¸PyTorchçš„å…¨è¿æ¥å±‚APIå¯¹æ¯”\n",
    "\n",
    "MindSporeä¸­æ„é€ å…¨è¿æ¥å±‚çš„APIä¸ºnn.Denseï¼ŒåŒºåˆ«äºPyTorchä¸­çš„nn.Linearï¼Œä¸”äºŒè€…æƒé‡åˆå§‹åŒ–ä¸åŒï¼š\n",
    "\n",
    "- MindSporeï¼šweighté»˜è®¤åˆå§‹åŒ–ä¸º'normal'åˆ†å¸ƒï¼Œbiasé»˜è®¤åˆå§‹åŒ–ä¸ºé›¶\n",
    "- PyTorchï¼šweighté»˜è®¤åˆå§‹åŒ–ä¸ºkaiming_uniformï¼Œbiasé»˜è®¤åˆå§‹åŒ–ä¸ºuniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef49a217-d48b-4a89-babd-ee2722745316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Cell):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = Dense(d_model, d_k * n_heads, dtype=mindspore.float16)\n",
    "        self.W_K = Dense(d_model, d_k * n_heads, dtype=mindspore.float16)\n",
    "        self.W_V = Dense(d_model, d_v * n_heads, dtype=mindspore.float16)\n",
    "        self.W_O = Dense(n_heads * d_v, d_model, dtype=mindspore.float16)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "\n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        # æ³¨æ„åŒºåˆ†MindSporeä¸­çš„Tensor.transposeä¸PyTorchä¸­çš„Tesor.transpose\n",
    "        # MindSporeä¸­çš„transposeä¸ºå¯¹æ‰€æœ‰ç»´åº¦è¿›è¡Œé‡æ’ï¼ŒPyTorchä¸­çš„transposeä¸ºå¯¹ä¸¤ä¸ªç»´åº¦è¿›è¡Œäº¤æ¢\n",
    "        # MindSporeä¸­å¯¹Tensorçš„ä¸¤ä¸ªç»´åº¦è¿›è¡Œäº¤æ¢çš„æ¥å£åº”ä¸ºswapaxes\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).swapaxes(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).swapaxes(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).swapaxes(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "        \n",
    "        attn_mask = attn_mask.expand_dims(1)\n",
    "        attn_mask = mint.tile(attn_mask, (1, n_heads, 1, 1))\n",
    "        \n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = self.attn(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.swapaxes(1, 2).view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.W_O(context)\n",
    "        return self.norm(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa752c",
   "metadata": {},
   "source": [
    "### åŸºäºä½ç½®çš„å‰é¦ˆç¥ç»ç½‘ç»œ ï¼ˆPosition-Wise Feed-Forward Networkï¼‰\n",
    "åŸºäºä½ç½®çš„å‰é¦ˆç¥ç»ç½‘ç»œè¢«ç”¨æ¥å¯¹è¾“å…¥ä¸­çš„æ¯ä¸ªä½ç½®è¿›è¡Œéçº¿æ€§å˜æ¢ã€‚å®ƒç”±ä¸¤ä¸ªçº¿æ€§å±‚ç»„æˆï¼Œå±‚ä¸å±‚ä¹‹é—´éœ€è¦ç»è¿‡GELUæ¿€æ´»å‡½æ•°ã€‚\n",
    "\n",
    "FFN(ğ‘¥)=GELU(ğ‘¥ğ‘Š1+ğ‘1)ğ‘Š2+ğ‘2\n",
    " \n",
    "ç›¸æ¯”å›ºå®šçš„GELUå‡½æ•°ï¼ŒåŸºäºä½ç½®çš„å‰é¦ˆç¥ç»ç½‘ç»œå¯ä»¥å¤„ç†æ›´åŠ å¤æ‚çš„å…³ç³»ï¼Œå¹¶ä¸”ç”±äºå‰é¦ˆç½‘ç»œæ˜¯åŸºäºä½ç½®çš„ï¼Œå¯ä»¥æ•è·åˆ°ä¸åŒä½ç½®çš„ä¿¡æ¯ï¼Œå¹¶ä¸ºæ¯ä¸ªä½ç½®æä¾›ä¸åŒçš„è½¬æ¢ã€‚\n",
    "\n",
    "#### MindSporeä¸PyTorchçš„GELUæ¿€æ´»å‡½æ•°å¯¹æ¯”\n",
    "\n",
    "å¯¹äºAPIçš„åŠŸèƒ½å¯¹é½ï¼Œæ³¨æ„MindSporeå’ŒPyTorchä¸­æœ‰äº›APIå³ä½¿åç§°å®è§‚åŠŸèƒ½ä¸€è‡´ï¼Œé»˜è®¤ä¼ å‚ä¼šå‡ºç°å·®åˆ«ï¼Œå¦‚GELUæ¥å£ã€‚\n",
    "\n",
    "- MindSporeï¼šå…¥å‚`approximate`ä¸º`boolean`ç±»å‹ï¼Œé»˜è®¤ä¸ºTrueï¼Œå¦‚æœä¸ºTrueé‡‡å–tanhæ–¹æ³•åšä¼˜åŒ–è¿‘ä¼¼ï¼Œåä¹‹é‡‡å–erfæ–¹æ³•\n",
    "- PyTorchï¼šå…¥å‚`approximate`ä¸º`string`ç±»å‹ï¼Œé»˜è®¤ä¸º'none'ï¼Œå¦‚æœä¸º'tanh'é‡‡å–tanhæ–¹æ³•è¿›è¡Œä¼˜åŒ–è¿‘ä¼¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ac0741-2515-413c-8aec-67a6ab654f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(Cell):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = Dense(d_model, d_ff, dtype=mindspore.float16)\n",
    "        self.fc2 = Dense(d_ff, d_model, dtype=mindspore.float16)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(self.activation(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b45114",
   "metadata": {},
   "source": [
    "### Encoder Layer\n",
    "æˆ‘ä»¬é¦–å…ˆå®ç°encoderä¸­çš„ä¸€ä¸ªå±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cac523ae-53a0-4678-a205-6f51d2e4f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Cell):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        # print('enc_inputs: ', enc_inputs.dtype)\n",
    "        enc_inputs = enc_inputs.astype(mindspore.float16)\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91516bc4",
   "metadata": {},
   "source": [
    "\n",
    "### BERT\n",
    "\n",
    "å°†ä¸Šé¢å®ç°çš„encoderå±‚å †å `n_layers`æ¬¡ï¼Œå¹¶æ·»åŠ token embeddingsã€position embeddingsä¸segment embeddingsã€‚\n",
    "\n",
    "#### BERT è¾“å‡º\n",
    "BERTä¼šé’ˆå¯¹æ¯ä¸€ä¸ªä½ç½®è¾“å‡ºå¤§å°ä¸ºhidden sizeçš„å‘é‡ï¼Œåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œä¼šæ ¹æ®ä»»åŠ¡å†…å®¹çš„ä¸åŒï¼Œé€‰å–ä¸åŒçš„å‘é‡æ”¾å…¥è¾“å‡ºå±‚ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¸€èˆ¬ç§°[CLS]ç»è¿‡çº¿æ€§å±‚+æ¿€æ´»å‡½æ•°tanhçš„è¾“å‡ºä¸ºpooler outputï¼Œç”¨äºå¥å­çº§åˆ«çš„åˆ†ç±»/å›å½’ä»»åŠ¡;  \n",
    "æˆ‘ä»¬ä¸€èˆ¬ç§°BERTè¾“å‡ºçš„æ¯ä¸ªä½ç½®å¯¹åº”çš„vectorä¸ºsequence output,ç”¨äºè¯è¯­çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2891fc39-ccf0-4f8c-875a-821ad85ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(Cell):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = BertEmbedding()\n",
    "        self.layers = mindspore.nn.CellList([EncoderLayer() for _ in range(n_layers)])\n",
    "        self.fc = Dense(d_model, d_model, dtype=mindspore.float16)\n",
    "        self.activ1 = nn.Tanh()\n",
    "        self.linear = Dense(d_model, d_model, dtype=mindspore.float16)\n",
    "        self.activ2 = nn.GELU()\n",
    "        self.norm = mindspore.nn.LayerNorm([d_model,], epsilon=1e-7, dtype=mindspore.float16)\n",
    "        self.classifier = Dense(d_model, 2, dtype=mindspore.float16)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.embedding_table\n",
    "        n_vocab, n_dim = embed_weight.shape\n",
    "        self.decoder = Dense(n_dim, n_vocab, has_bias=False, dtype=mindspore.float16)\n",
    "        self.decoder.weight = embed_weight.to(mindspore.float16)\n",
    "        self.decoder_bias = mindspore.Parameter(mint.zeros(n_vocab, dtype=mindspore.float16), 'decoder_bias')\n",
    "\n",
    "    def construct(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0]))  # [batch_size, d_model]\n",
    "        logits_clsf = self.classifier(h_pooled)  # [batch_size, 2]\n",
    "        \n",
    "        # ä½¿ç”¨ops.gatheræ›¿ä»£gather_elementsï¼Œæ— éœ€æ‰©å±•masked_posä¸ºä¸‰ç»´\n",
    "\n",
    "        h_masked = mindspore.ops.gather(output, masked_pos, 1, batch_dims=1)  # [batch_size, max_pred, d_model]\n",
    "\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias  # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9391e0d9-f019-4d3e-9c6c-fb57a3b6a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Parameters\n",
    "maxlen = 30 # maximum of length\n",
    "batch_size = 6\n",
    "max_pred = 5  # max tokens of prediction\n",
    "n_layers = 6 # number of Encoder of Encoder Layer\n",
    "n_heads = 12 # number of heads in Multi-Head Attention\n",
    "d_model = 768 # Embedding Size\n",
    "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7c275",
   "metadata": {},
   "source": [
    "### æ„å»ºè¯å…¸\n",
    "å°†æ¯ä¸ªè¯å…ƒæ˜ å°„åˆ°æ•°å­—ç´¢å¼•ä¸­ï¼Œè¯å…ƒå’Œæ•°å­—ç´¢å¼•æ‰€æ„æˆçš„é›†åˆå«åšè¯å…¸ï¼ˆvocabularyï¼‰ã€‚\n",
    "\n",
    "åœ¨æ„å»ºè¯å…¸ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†4ä¸ªç‰¹æ®Šè¯å…ƒã€‚\n",
    "[PAD]ï¼šå¡«å……è¯å…ƒï¼ˆpaddingï¼‰ï¼Œå½“å¥å­é•¿åº¦ä¸å¤Ÿæ—¶å°†å¥å­å¡«å……è‡³ç»Ÿä¸€é•¿åº¦ï¼›  \n",
    "[CLS]ï¼šå¥å­çº§åˆ«ä¿¡æ¯ï¼›  \n",
    "[SEP]: ç»“æŸè¯å…ƒï¼Œç”¨æ¥æ ‡æ³¨ä¸€ä¸ªå¥å­çš„ç»“æŸï¼›  \n",
    "[MASK]: maskè¯å…ƒï¼›\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24608b11-440c-4fb6-b070-45ff3d82c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Hello, how are you? I am Romeo.\\n'\n",
    "    'Hello, Romeo My name is Juliet. Nice to meet you.\\n'\n",
    "    'Nice meet you too. How are you today?\\n'\n",
    "    'Great. My baseball team won the competition.\\n'\n",
    "    'Oh Congratulations, Juliet\\n'\n",
    "    'Thanks you Romeo'\n",
    ")\n",
    "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # filter '.', ',', '?', '!'\n",
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
    "for i, w in enumerate(word_list):\n",
    "    word_dict[w] = i + 4\n",
    "number_dict = {i: w for i, w in enumerate(word_dict)}\n",
    "vocab_size = len(word_dict)\n",
    "token_list = list()\n",
    "for sentence in sentences:\n",
    "    arr = [word_dict[s] for s in sentence.split()]\n",
    "    token_list.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4fa44",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è®­ç»ƒ\n",
    "å®ä¾‹åŒ–BERTæ¨¡å‹ã€‚\n",
    "\n",
    "### å®šä¹‰æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨ã€‚\n",
    "\n",
    "- æŸå¤±å‡½æ•°ï¼šå®šä¹‰å¦‚ä½•è®¡ç®—æ¨¡å‹è¾“å‡º(logits)ä¸ç›®æ ‡(targets)ä¹‹é—´çš„è¯¯å·®ï¼Œè¿™é‡Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆCrossEntropyLossï¼‰  \n",
    "- ä¼˜åŒ–å™¨ï¼šMindSporeå°†æ¨¡å‹ä¼˜åŒ–ç®—æ³•çš„å®ç°ç§°ä¸ºä¼˜åŒ–å™¨ã€‚ä¼˜åŒ–å™¨å†…éƒ¨å®šä¹‰äº†æ¨¡å‹çš„å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ï¼ˆå³æ¢¯åº¦å¦‚ä½•æ›´æ–°è‡³æ¨¡å‹å‚æ•°ï¼‰ï¼Œæ‰€æœ‰ä¼˜åŒ–é€»è¾‘éƒ½å°è£…åœ¨ä¼˜åŒ–å™¨å¯¹è±¡ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4e30ab-9e7d-4868-893f-b160cf090959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()\n",
    "criterion = mindspore.ops.SoftmaxCrossEntropyWithLogits()\n",
    "optimizer = mindspore.nn.Adam(model.trainable_params(), learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346774e",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è®­ç»ƒé€»è¾‘\n",
    "\n",
    "MindSporeåœ¨æ¨¡å‹è®­ç»ƒä¸­é‡‡å–å‡½æ•°å¼ç¼–ç¨‹ï¼Œå³ï¼š\n",
    "\n",
    "1. Network+loss functionç›´æ¥æ„é€ æ­£å‘å‡½æ•°\n",
    "2. å‡½æ•°å˜æ¢ï¼Œè·å¾—æ¢¯åº¦è®¡ç®—ï¼ˆåå‘ä¼ æ’­ï¼‰å‡½æ•°\n",
    "3. æ„é€ è®­ç»ƒè¿‡ç¨‹å‡½æ•°\n",
    "4. è°ƒç”¨å‡½æ•°è¿›è¡Œè®­ç»ƒ\n",
    "\n",
    "å’ŒPyTorchç›¸æ¯”ï¼Œä¸¤ä¸ªæ¡†æ¶åœ¨å‰å‘è®¡ç®—çš„è°ƒç”¨æ–¹å¼ä¸€è‡´ï¼Œä½†åœ¨åå‘è®¡ç®—ä¸­MindSporeé‡‡ç”¨å‡½æ•°å¾®åˆ†ï¼ŒPyTorché‡‡ç”¨æ•°æ®æµå¾®åˆ†ï¼Œæœ€ååœ¨æ¢¯åº¦æ›´æ–°ä¸­ï¼ŒäºŒè€…æµç¨‹ç›¸åŒï¼Œä½†åº•å±‚å®ç°é€»è¾‘ä¸åŒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef3603-8154-495b-9e00-5916c65c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import amp\n",
    "\n",
    "loss_scaler = amp.StaticLossScaler(scale_value=2**10)\n",
    "\n",
    "# æ„é€ æ­£å‘å‡½æ•°\n",
    "def forward(input_ids, segment_ids, masked_pos, masked_tokens, isNext):\n",
    "    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "    logits_lm = mint.reshape(logits_lm, (-1, vocab_size)) # [batch_size * max_pred, n_vocab]\n",
    "    masked_tokens = mint.reshape(masked_tokens, (-1,)) # [batch_size * max_pred]\n",
    "    masked_tokens_onehot = nn.functional.one_hot(masked_tokens.astype(mindspore.int32), vocab_size)\n",
    "    \n",
    "    loss_lm = criterion(logits_lm, masked_tokens_onehot.to(logits_lm.dtype))[0]\n",
    "    loss_lm = loss_lm.mean()\n",
    "    # scaled_loss_lm = loss_scaler.scale(loss_lm)\n",
    "\n",
    "    isNext_onehot = nn.functional.one_hot(isNext.astype(mindspore.int32), 2)\n",
    "    loss_clsf = criterion(logits_clsf, isNext_onehot.to(logits_clsf.dtype))[0]\n",
    "    loss_clsf = loss_clsf.mean()\n",
    "    # scaled_loss_clsf = loss_scaler.scale(loss_clsf)\n",
    "\n",
    "    return loss_scaler.scale(loss_lm + loss_clsf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c1c152d-d4f0-4a66-b3e2-5cbf76d15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡½æ•°å˜æ¢ï¼Œè·å¾—å¾®åˆ†å‡½æ•°\n",
    "grad_fn = mindspore.value_and_grad(forward, None, optimizer.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa084dc",
   "metadata": {},
   "source": [
    "MindSporeæä¾›äº†jitè£…é¥°å™¨ï¼Œå¯ä»¥é€šè¿‡ä¿®é¥°Pythonå‡½æ•°æˆ–è€…Pythonç±»çš„æˆå‘˜å‡½æ•°ï¼Œä½¿å…¶è¢«ç¼–è¯‘æˆè®¡ç®—å›¾ï¼Œé€šè¿‡å›¾ä¼˜åŒ–ç­‰æŠ€æœ¯æé«˜è¿è¡Œé€Ÿåº¦ã€‚åœ¨è¿™ç§æ–¹å¼ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°å¯¹æƒ³è¦è¿›è¡Œæ€§èƒ½ä¼˜åŒ–çš„æ¨¡å—æ¥è¿›è¡Œå›¾ç¼–è¯‘åŠ é€Ÿï¼Œè€Œæ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ä»æ—§ä½¿ç”¨è§£é‡Šæ‰§è¡Œæ–¹å¼ï¼Œä¸ä¸¢å¤±åŠ¨æ€å›¾çš„çµæ´»æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2cd05a5-b034-46cd-980e-dfb15e7b6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰å•æ­¥è®­ç»ƒé€»è¾‘\n",
    "\n",
    "def train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext):\n",
    "    # åå‘ä¼ æ’­è·å–æ¢¯åº¦\n",
    "    loss, grads = grad_fn(input_ids, segment_ids, masked_pos, masked_tokens, isNext)\n",
    "    unscaled_loss = loss_scaler.unscale(loss)\n",
    "    unscaled_grads = loss_scaler.unscale(grads)\n",
    "    # æ¨¡å‹æƒé‡æ›´æ–°\n",
    "    optimizer(unscaled_grads)\n",
    "    return unscaled_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bf550b-8239-440d-9fda-c556dee4552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001\n",
      ".....loss: 3.855\n",
      "time: 74.99734854698181\n",
      "Epoch: 0001 cost = 3.855469\n",
      "Epoch: 0002\n",
      "loss: 2.363\n",
      "time: 0.5860943794250488\n",
      "Epoch: 0002 cost = 2.363281\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºæ•°æ®\n",
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(mindspore.Tensor, zip(*batch))\n",
    "\n",
    "# å¯åŠ¨æ¨¡å‹è®­ç»ƒ\n",
    "import time\n",
    "model.set_train()\n",
    "for epoch in range(2):\n",
    "    print('Epoch:', '%04d' % (epoch + 1))\n",
    "    s_time = time.time()\n",
    "    loss = train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext)\n",
    "    print('loss:', loss.asnumpy())\n",
    "\n",
    "    e_time = time.time()\n",
    "    print('time:', e_time - s_time)\n",
    "    # loss = train_step(input_ids, segment_ids, masked_pos, masked_tokens, isNext) # for sentence classification\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0570e5",
   "metadata": {},
   "source": [
    "### ä»¥batchä¸­çš„ç¬¬ä¸€ç»„è¯­å¥batch[0]ä¸ºä¾‹ï¼Œè¿›è¡Œæµ‹è¯•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8afdd6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡æœ¬å†…å®¹ï¼š\n",
      " Hello, how are you? I am Romeo.\n",
      "Hello, Romeo My name is Juliet. Nice to meet you.\n",
      "Nice meet you too. How are you today?\n",
      "Great. My baseball team won the competition.\n",
      "Oh Congratulations, Juliet\n",
      "Thanks you Romeo\n",
      "æ©ç ä¹‹åçš„æ–‡æœ¬ï¼š\n",
      "['[CLS]', 'hello', 'romeo', '[MASK]', 'name', 'is', 'juliet', 'nice', 'to', 'meet', 'you', '[SEP]', '[MASK]', 'you', 'romeo', '[SEP]']\n",
      "masked tokens list :  [Tensor(shape=[], dtype=Int64, value= 6), Tensor(shape=[], dtype=Int64, value= 7)]\n",
      "predict masked tokens list :  []\n",
      ".isNext :  False\n",
      "predict isNext :  True\n"
     ]
    }
   ],
   "source": [
    "# Predict mask tokens ans isNext\n",
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(mindspore.Tensor, zip(batch[0]))\n",
    "print(f\"æ–‡æœ¬å†…å®¹ï¼š\\n {text}\")\n",
    "print(\"æ©ç ä¹‹åçš„æ–‡æœ¬ï¼š\")\n",
    "print([number_dict[int(w.asnumpy())] for w in input_ids[0] if number_dict[int(w.asnumpy())] != '[PAD]'])\n",
    "\n",
    "\n",
    "logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "logits_lm_reshaped = mint.reshape(logits_lm, (-1, vocab_size)) # [batch_size * max_pred, n_vocab]\n",
    "masked_tokens_reshaped = mint.reshape(masked_tokens, (-1,)) # [batch_size * max_pred]\n",
    "masked_tokens_onehot = nn.functional.one_hot(masked_tokens_reshaped.astype(mindspore.int32), vocab_size)\n",
    "loss_lm = criterion(logits_lm_reshaped, masked_tokens_onehot.to(logits_lm.dtype))[0]\n",
    "\n",
    "loss_lm = loss_lm.mean()\n",
    "\n",
    "logits_lm = logits_lm.argmax(2)[0].asnumpy()\n",
    "\n",
    "print('masked tokens list : ', [pos for pos in masked_tokens[0] if pos != 0])\n",
    "print('predict masked tokens list : ', [pos for pos in logits_lm if pos != 0])\n",
    "\n",
    "logits_clsf = logits_clsf.argmax(1).asnumpy()[0]\n",
    "\n",
    "print('isNext : ', True if isNext else False)\n",
    "print('predict isNext : ',True if logits_clsf else False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
